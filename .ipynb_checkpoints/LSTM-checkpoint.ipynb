{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b868ea2c-e367-43c2-a2e7-e592dfece1ed",
    "_uuid": "81d7e2d29f910143ac27e4fd3b31de82818f37a6"
   },
   "outputs": [],
   "source": [
    "#Load libs\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0ff6bdbc-8138-4cdd-ae1e-20a06b17e04e",
    "_uuid": "d953a3b6145bfedeee9c94b1ecebf52511369b37"
   },
   "source": [
    "**Ok so my goal here is to predict the BTC and ETH price (and eventually get billions of $ )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "9b644dd6-fb3f-4260-85ce-fb7ba1b61606",
    "_uuid": "985de2c9ded00014431f812de337c01d5d50e58d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Market Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nov 07, 2017</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.69</td>\n",
       "      <td>11,312,200</td>\n",
       "      <td>352,178,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nov 06, 2017</td>\n",
       "      <td>3.46</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.36</td>\n",
       "      <td>3.52</td>\n",
       "      <td>12,291,000</td>\n",
       "      <td>345,746,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nov 05, 2017</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3.45</td>\n",
       "      <td>9,798,490</td>\n",
       "      <td>360,517,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nov 04, 2017</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.62</td>\n",
       "      <td>11,619,500</td>\n",
       "      <td>365,254,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nov 03, 2017</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.97</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.68</td>\n",
       "      <td>14,090,800</td>\n",
       "      <td>320,550,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Open  High   Low  Close      Volume   Market Cap\n",
       "0  Nov 07, 2017  3.52  3.72  3.42   3.69  11,312,200  352,178,000\n",
       "1  Nov 06, 2017  3.46  3.65  3.36   3.52  12,291,000  345,746,000\n",
       "2  Nov 05, 2017  3.61  3.62  3.39   3.45   9,798,490  360,517,000\n",
       "3  Nov 04, 2017  3.65  3.79  3.44   3.62  11,619,500  365,254,000\n",
       "4  Nov 03, 2017  3.21  3.97  3.02   3.68  14,090,800  320,550,000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets load the daily prices\n",
    "\n",
    "btc = pd.read_csv('bitcoin_price.csv')\n",
    "eth = pd.read_csv('ethereum_price.csv')\n",
    "bch = pd.read_csv('bitcoin_cash_price.csv')\n",
    "#bitconn=pd.read_csv('bitconnect_price.csv')\n",
    "dash=pd.read_csv('dash_price.csv')\n",
    "ethcls=pd.read_csv('ethereum_classic_price.csv')\n",
    "iota = pd.read_csv(\"iota_price.csv\")\n",
    "litecoin = pd.read_csv(\"litecoin_price.csv\")\n",
    "monero = pd.read_csv(\"monero_price.csv\")\n",
    "nem = pd.read_csv(\"nem_price.csv\")\n",
    "neo = pd.read_csv(\"neo_price.csv\")\n",
    "numeraire = pd.read_csv(\"numeraire_price.csv\")\n",
    "ripple = pd.read_csv(\"ripple_price.csv\")\n",
    "stratis = pd.read_csv(\"stratis_price.csv\")\n",
    "waves = pd.read_csv(\"waves_price.csv\")\n",
    "waves.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_cell_guid": "3d233791-e344-4db5-80e2-269a3cfc5f5b",
    "_uuid": "ef53f790d6a606682c50385f78d54c1962d3b850"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Market Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>Apr 28, 2013</td>\n",
       "      <td>135.30</td>\n",
       "      <td>135.98</td>\n",
       "      <td>132.10</td>\n",
       "      <td>134.21</td>\n",
       "      <td>-</td>\n",
       "      <td>1,500,520,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>Apr 29, 2013</td>\n",
       "      <td>134.44</td>\n",
       "      <td>147.49</td>\n",
       "      <td>134.00</td>\n",
       "      <td>144.54</td>\n",
       "      <td>-</td>\n",
       "      <td>1,491,160,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>Apr 30, 2013</td>\n",
       "      <td>144.00</td>\n",
       "      <td>146.93</td>\n",
       "      <td>134.05</td>\n",
       "      <td>139.00</td>\n",
       "      <td>-</td>\n",
       "      <td>1,597,780,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>May 01, 2013</td>\n",
       "      <td>139.00</td>\n",
       "      <td>139.89</td>\n",
       "      <td>107.72</td>\n",
       "      <td>116.99</td>\n",
       "      <td>-</td>\n",
       "      <td>1,542,820,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>May 02, 2013</td>\n",
       "      <td>116.38</td>\n",
       "      <td>125.60</td>\n",
       "      <td>92.28</td>\n",
       "      <td>105.21</td>\n",
       "      <td>-</td>\n",
       "      <td>1,292,190,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date    Open    High     Low   Close Volume     Market Cap\n",
       "1654  Apr 28, 2013  135.30  135.98  132.10  134.21      -  1,500,520,000\n",
       "1653  Apr 29, 2013  134.44  147.49  134.00  144.54      -  1,491,160,000\n",
       "1652  Apr 30, 2013  144.00  146.93  134.05  139.00      -  1,597,780,000\n",
       "1651  May 01, 2013  139.00  139.89  107.72  116.99      -  1,542,820,000\n",
       "1650  May 02, 2013  116.38  125.60   92.28  105.21      -  1,292,190,000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data is in reverse order\n",
    "btc = btc.iloc[::-1]\n",
    "eth = eth.iloc[::-1]\n",
    "bch = bch.iloc[::-1]\n",
    "dash= dash.iloc[::-1]\n",
    "ethcls= ethcls.iloc[::-1]\n",
    "iota = iota.iloc[::-1]\n",
    "litecoin = litecoin.iloc[::-1]\n",
    "monero = monero.iloc[::-1]\n",
    "nem = nem.iloc[::-1]\n",
    "neo = neo.iloc[::-1]\n",
    "numeraire = numeraire.iloc[::-1]\n",
    "ripple = ripple.iloc[::-1]\n",
    "stratis = stratis.iloc[::-1]\n",
    "waves = waves.iloc[::-1]\n",
    "\n",
    "#bitconn=bitconn.iloc[::-1]\n",
    "btc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "_cell_guid": "7ef15f02-9aa0-447a-b7eb-a7518778b5d4",
    "_uuid": "5687758610a6ffa564a35fafa65024b79695e4c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524, 4)\n",
      "[[[ -9.91735537]\n",
      "  [  4.5112782 ]\n",
      "  [ -4.95867769]]\n",
      "\n",
      " [[-18.34862385]\n",
      "  [ 28.68217054]\n",
      "  [-33.24963303]]]\n",
      "[[[-6.56934307]\n",
      "  [ 2.39726027]\n",
      "  [-8.75912409]]\n",
      "\n",
      " [[ 0.36363636]\n",
      "  [ 3.27272727]\n",
      "  [-5.10948905]]]\n",
      "Xtest 105\n",
      "Ytest 105\n",
      "[ 0.  0.  1.  1.  1.  1.  1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#getting the 4 price-related features from the dataframe\n",
    "features = waves[[\"Open\",\"High\",\"Low\",\"Close\"]].values\n",
    "print(features.shape)\n",
    "\n",
    "#we change the data to have something more generalizeable, lets say [ %variation , %high, %low]\n",
    "price_variation = (1- (features[:,0]/features[:,3]))*100\n",
    "highs = (features[:,1]/np.maximum(features[:,0],features[:,3]) -1)*100\n",
    "lows = (features[:,2]/np.minimum(features[:,0],features[:,3]) -1)*100\n",
    "\n",
    "X_train = np.array([price_variation , highs, lows]).transpose()\n",
    "#little trick to make X_train a 3 dimensional array for LSTM input shape\n",
    "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
    "#print(len(X_train))\n",
    "X_train,X_test = np.split(X_train,[int(.8*len(X_train))])\n",
    "print(X_train[:2])\n",
    "#print(len(X_train))\n",
    "print(X_test[:2])\n",
    "print('Xtest',len(X_test))\n",
    "\n",
    "#We generate Y_train. For this update, we will only determine if the trend is up or down for 2 days ahead\n",
    "Y_train = np.array((np.sign((features[2:,3]/features[:-2,3]-1))+1)/2)\n",
    "#print(len(Y_train))\n",
    "Y_train,Y_test = np.split(Y_train,[int(.8*len(Y_train))])\n",
    "#print(len(Y_train))\n",
    "print('Ytest',len(Y_test))\n",
    "print(Y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "_cell_guid": "2be1c429-1009-4b97-b9d9-34802492ebbc",
    "_uuid": "aee977b2a43da83909a4dbe075141ab13009e9b5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets make a simple lstm model \n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100,\n",
    "               input_shape = (None,1),\n",
    "               return_sequences = True\n",
    "              ))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "_cell_guid": "55033866-34e4-4686-a61c-c08f7f010b6c",
    "_uuid": "fa0d305d23012c0141f80306b832ba6971d84877",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 396 samples, validate on 21 samples\n",
      "Epoch 1/500\n",
      "396/396 [==============================] - 4s - loss: 0.2493 - val_loss: 0.2512\n",
      "Epoch 2/500\n",
      "396/396 [==============================] - 0s - loss: 0.2492 - val_loss: 0.2502\n",
      "Epoch 3/500\n",
      "396/396 [==============================] - 0s - loss: 0.2488 - val_loss: 0.2507\n",
      "Epoch 4/500\n",
      "396/396 [==============================] - 0s - loss: 0.2487 - val_loss: 0.2516\n",
      "Epoch 5/500\n",
      "396/396 [==============================] - 0s - loss: 0.2485 - val_loss: 0.2512\n",
      "Epoch 6/500\n",
      "396/396 [==============================] - 0s - loss: 0.2482 - val_loss: 0.2520\n",
      "Epoch 7/500\n",
      "396/396 [==============================] - 0s - loss: 0.2478 - val_loss: 0.2531\n",
      "Epoch 8/500\n",
      "396/396 [==============================] - 0s - loss: 0.2476 - val_loss: 0.2533\n",
      "Epoch 9/500\n",
      "396/396 [==============================] - 0s - loss: 0.2470 - val_loss: 0.2555\n",
      "Epoch 10/500\n",
      "396/396 [==============================] - 0s - loss: 0.2466 - val_loss: 0.2538\n",
      "Epoch 11/500\n",
      "396/396 [==============================] - 0s - loss: 0.2460 - val_loss: 0.2579\n",
      "Epoch 12/500\n",
      "396/396 [==============================] - 0s - loss: 0.2459 - val_loss: 0.2526\n",
      "Epoch 13/500\n",
      "396/396 [==============================] - 0s - loss: 0.2458 - val_loss: 0.2693\n",
      "Epoch 14/500\n",
      "396/396 [==============================] - 0s - loss: 0.2462 - val_loss: 0.2515\n",
      "Epoch 15/500\n",
      "396/396 [==============================] - 0s - loss: 0.2459 - val_loss: 0.2648\n",
      "Epoch 16/500\n",
      "396/396 [==============================] - 0s - loss: 0.2453 - val_loss: 0.2564\n",
      "Epoch 17/500\n",
      "396/396 [==============================] - 0s - loss: 0.2439 - val_loss: 0.2615\n",
      "Epoch 18/500\n",
      "396/396 [==============================] - 0s - loss: 0.2437 - val_loss: 0.2579\n",
      "Epoch 19/500\n",
      "396/396 [==============================] - 0s - loss: 0.2431 - val_loss: 0.2660\n",
      "Epoch 20/500\n",
      "396/396 [==============================] - 0s - loss: 0.2436 - val_loss: 0.2561\n",
      "Epoch 21/500\n",
      "396/396 [==============================] - 0s - loss: 0.2434 - val_loss: 0.2719\n",
      "Epoch 22/500\n",
      "396/396 [==============================] - 0s - loss: 0.2432 - val_loss: 0.2537\n",
      "Epoch 23/500\n",
      "396/396 [==============================] - 0s - loss: 0.2442 - val_loss: 0.2731\n",
      "Epoch 24/500\n",
      "396/396 [==============================] - 0s - loss: 0.2427 - val_loss: 0.2559\n",
      "Epoch 25/500\n",
      "396/396 [==============================] - 0s - loss: 0.2432 - val_loss: 0.2672\n",
      "Epoch 26/500\n",
      "396/396 [==============================] - 0s - loss: 0.2422 - val_loss: 0.2591\n",
      "Epoch 27/500\n",
      "396/396 [==============================] - 0s - loss: 0.2417 - val_loss: 0.2651\n",
      "Epoch 28/500\n",
      "396/396 [==============================] - 0s - loss: 0.2404 - val_loss: 0.2619\n",
      "Epoch 29/500\n",
      "396/396 [==============================] - 0s - loss: 0.2409 - val_loss: 0.2676\n",
      "Epoch 30/500\n",
      "396/396 [==============================] - 0s - loss: 0.2418 - val_loss: 0.2586\n",
      "Epoch 31/500\n",
      "396/396 [==============================] - 0s - loss: 0.2404 - val_loss: 0.2784\n",
      "Epoch 32/500\n",
      "396/396 [==============================] - 0s - loss: 0.2416 - val_loss: 0.2523\n",
      "Epoch 33/500\n",
      "396/396 [==============================] - 0s - loss: 0.2424 - val_loss: 0.2828\n",
      "Epoch 34/500\n",
      "396/396 [==============================] - 0s - loss: 0.2421 - val_loss: 0.2559\n",
      "Epoch 35/500\n",
      "396/396 [==============================] - 0s - loss: 0.2416 - val_loss: 0.2728\n",
      "Epoch 36/500\n",
      "396/396 [==============================] - 0s - loss: 0.2406 - val_loss: 0.2614\n",
      "Epoch 37/500\n",
      "396/396 [==============================] - 0s - loss: 0.2399 - val_loss: 0.2681\n",
      "Epoch 38/500\n",
      "396/396 [==============================] - 0s - loss: 0.2393 - val_loss: 0.2624\n",
      "Epoch 39/500\n",
      "396/396 [==============================] - 0s - loss: 0.2400 - val_loss: 0.2713\n",
      "Epoch 40/500\n",
      "396/396 [==============================] - 0s - loss: 0.2394 - val_loss: 0.2587\n",
      "Epoch 41/500\n",
      "396/396 [==============================] - 0s - loss: 0.2397 - val_loss: 0.2790\n",
      "Epoch 42/500\n",
      "396/396 [==============================] - 0s - loss: 0.2403 - val_loss: 0.2536\n",
      "Epoch 43/500\n",
      "396/396 [==============================] - 0s - loss: 0.2393 - val_loss: 0.2862\n",
      "Epoch 44/500\n",
      "396/396 [==============================] - 0s - loss: 0.2404 - val_loss: 0.2552\n",
      "Epoch 45/500\n",
      "396/396 [==============================] - 0s - loss: 0.2385 - val_loss: 0.2794\n",
      "Epoch 46/500\n",
      "396/396 [==============================] - 0s - loss: 0.2378 - val_loss: 0.2603\n",
      "Epoch 47/500\n",
      "396/396 [==============================] - 0s - loss: 0.2381 - val_loss: 0.2763\n",
      "Epoch 48/500\n",
      "396/396 [==============================] - 0s - loss: 0.2371 - val_loss: 0.2603\n",
      "Epoch 49/500\n",
      "396/396 [==============================] - 0s - loss: 0.2369 - val_loss: 0.2817\n",
      "Epoch 50/500\n",
      "396/396 [==============================] - 0s - loss: 0.2374 - val_loss: 0.2588\n",
      "Epoch 51/500\n",
      "396/396 [==============================] - 0s - loss: 0.2378 - val_loss: 0.2866\n",
      "Epoch 52/500\n",
      "396/396 [==============================] - 0s - loss: 0.2382 - val_loss: 0.2531\n",
      "Epoch 53/500\n",
      "396/396 [==============================] - 0s - loss: 0.2402 - val_loss: 0.2890\n",
      "Epoch 54/500\n",
      "396/396 [==============================] - 0s - loss: 0.2409 - val_loss: 0.2589\n",
      "Epoch 55/500\n",
      "396/396 [==============================] - 0s - loss: 0.2376 - val_loss: 0.2779\n",
      "Epoch 56/500\n",
      "396/396 [==============================] - 0s - loss: 0.2381 - val_loss: 0.2633\n",
      "Epoch 57/500\n",
      "396/396 [==============================] - 0s - loss: 0.2383 - val_loss: 0.2730\n",
      "Epoch 58/500\n",
      "396/396 [==============================] - 0s - loss: 0.2379 - val_loss: 0.2620\n",
      "Epoch 59/500\n",
      "396/396 [==============================] - 0s - loss: 0.2374 - val_loss: 0.2778\n",
      "Epoch 60/500\n",
      "396/396 [==============================] - 0s - loss: 0.2370 - val_loss: 0.2628\n",
      "Epoch 61/500\n",
      "396/396 [==============================] - 0s - loss: 0.2359 - val_loss: 0.2736\n",
      "Epoch 62/500\n",
      "396/396 [==============================] - 0s - loss: 0.2364 - val_loss: 0.2632\n",
      "Epoch 63/500\n",
      "396/396 [==============================] - 0s - loss: 0.2359 - val_loss: 0.2777\n",
      "Epoch 64/500\n",
      "396/396 [==============================] - 0s - loss: 0.2365 - val_loss: 0.2605\n",
      "Epoch 65/500\n",
      "396/396 [==============================] - 0s - loss: 0.2355 - val_loss: 0.2899\n",
      "Epoch 66/500\n",
      "396/396 [==============================] - 0s - loss: 0.2368 - val_loss: 0.2521\n",
      "Epoch 67/500\n",
      "396/396 [==============================] - 0s - loss: 0.2377 - val_loss: 0.2958\n",
      "Epoch 68/500\n",
      "396/396 [==============================] - 0s - loss: 0.2384 - val_loss: 0.2576\n",
      "Epoch 69/500\n",
      "396/396 [==============================] - 0s - loss: 0.2342 - val_loss: 0.2785\n",
      "Epoch 70/500\n",
      "396/396 [==============================] - 0s - loss: 0.2352 - val_loss: 0.2627\n",
      "Epoch 71/500\n",
      "396/396 [==============================] - 0s - loss: 0.2373 - val_loss: 0.2826\n",
      "Epoch 72/500\n",
      "396/396 [==============================] - 0s - loss: 0.2343 - val_loss: 0.2604\n",
      "Epoch 73/500\n",
      "396/396 [==============================] - 0s - loss: 0.2355 - val_loss: 0.2824\n",
      "Epoch 74/500\n",
      "396/396 [==============================] - 0s - loss: 0.2357 - val_loss: 0.2589\n",
      "Epoch 75/500\n",
      "396/396 [==============================] - 0s - loss: 0.2342 - val_loss: 0.2807\n",
      "Epoch 76/500\n",
      "396/396 [==============================] - 0s - loss: 0.2350 - val_loss: 0.2605\n",
      "Epoch 77/500\n",
      "396/396 [==============================] - 0s - loss: 0.2353 - val_loss: 0.2818\n",
      "Epoch 78/500\n",
      "396/396 [==============================] - 0s - loss: 0.2365 - val_loss: 0.2599\n",
      "Epoch 79/500\n",
      "396/396 [==============================] - 0s - loss: 0.2367 - val_loss: 0.2857\n",
      "Epoch 80/500\n",
      "396/396 [==============================] - 0s - loss: 0.2345 - val_loss: 0.2564\n",
      "Epoch 81/500\n",
      "396/396 [==============================] - 0s - loss: 0.2370 - val_loss: 0.2958\n",
      "Epoch 82/500\n",
      "396/396 [==============================] - 0s - loss: 0.2360 - val_loss: 0.2563\n",
      "Epoch 83/500\n",
      "396/396 [==============================] - 0s - loss: 0.2353 - val_loss: 0.2828\n",
      "Epoch 84/500\n",
      "396/396 [==============================] - 0s - loss: 0.2352 - val_loss: 0.2626\n",
      "Epoch 85/500\n",
      "396/396 [==============================] - 0s - loss: 0.2325 - val_loss: 0.2760\n",
      "Epoch 86/500\n",
      "396/396 [==============================] - 0s - loss: 0.2342 - val_loss: 0.2657\n",
      "Epoch 87/500\n",
      "396/396 [==============================] - 0s - loss: 0.2325 - val_loss: 0.2793\n",
      "Epoch 88/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396/396 [==============================] - 0s - loss: 0.2331 - val_loss: 0.2622\n",
      "Epoch 89/500\n",
      "396/396 [==============================] - 0s - loss: 0.2332 - val_loss: 0.2837\n",
      "Epoch 90/500\n",
      "396/396 [==============================] - 0s - loss: 0.2335 - val_loss: 0.2618\n",
      "Epoch 91/500\n",
      "396/396 [==============================] - 0s - loss: 0.2330 - val_loss: 0.2876\n",
      "Epoch 92/500\n",
      "396/396 [==============================] - 0s - loss: 0.2342 - val_loss: 0.2555\n",
      "Epoch 93/500\n",
      "396/396 [==============================] - 0s - loss: 0.2359 - val_loss: 0.2999\n",
      "Epoch 94/500\n",
      "396/396 [==============================] - 0s - loss: 0.2366 - val_loss: 0.2576\n",
      "Epoch 95/500\n",
      "396/396 [==============================] - 0s - loss: 0.2330 - val_loss: 0.2875\n",
      "Epoch 96/500\n",
      "396/396 [==============================] - 0s - loss: 0.2334 - val_loss: 0.2618\n",
      "Epoch 97/500\n",
      "396/396 [==============================] - 0s - loss: 0.2312 - val_loss: 0.2835\n",
      "Epoch 98/500\n",
      "396/396 [==============================] - 0s - loss: 0.2323 - val_loss: 0.2628\n",
      "Epoch 99/500\n",
      "396/396 [==============================] - 0s - loss: 0.2330 - val_loss: 0.2837\n",
      "Epoch 100/500\n",
      "396/396 [==============================] - 0s - loss: 0.2329 - val_loss: 0.2628\n",
      "Epoch 101/500\n",
      "396/396 [==============================] - 0s - loss: 0.2316 - val_loss: 0.2833\n",
      "Epoch 102/500\n",
      "396/396 [==============================] - 0s - loss: 0.2329 - val_loss: 0.2625\n",
      "Epoch 103/500\n",
      "396/396 [==============================] - 0s - loss: 0.2349 - val_loss: 0.2927\n",
      "Epoch 104/500\n",
      "396/396 [==============================] - 0s - loss: 0.2324 - val_loss: 0.2587\n",
      "Epoch 105/500\n",
      "396/396 [==============================] - 0s - loss: 0.2312 - val_loss: 0.2893\n",
      "Epoch 106/500\n",
      "396/396 [==============================] - 0s - loss: 0.2345 - val_loss: 0.2613\n",
      "Epoch 107/500\n",
      "396/396 [==============================] - 0s - loss: 0.2339 - val_loss: 0.2822\n",
      "Epoch 108/500\n",
      "396/396 [==============================] - 0s - loss: 0.2315 - val_loss: 0.2650\n",
      "Epoch 109/500\n",
      "396/396 [==============================] - 0s - loss: 0.2321 - val_loss: 0.2806\n",
      "Epoch 110/500\n",
      "396/396 [==============================] - 0s - loss: 0.2328 - val_loss: 0.2638\n",
      "Epoch 111/500\n",
      "396/396 [==============================] - 0s - loss: 0.2317 - val_loss: 0.2890\n",
      "Epoch 112/500\n",
      "396/396 [==============================] - 0s - loss: 0.2313 - val_loss: 0.2581\n",
      "Epoch 113/500\n",
      "396/396 [==============================] - 0s - loss: 0.2328 - val_loss: 0.2969\n",
      "Epoch 114/500\n",
      "396/396 [==============================] - 0s - loss: 0.2350 - val_loss: 0.2608\n",
      "Epoch 115/500\n",
      "396/396 [==============================] - 0s - loss: 0.2334 - val_loss: 0.2871\n",
      "Epoch 116/500\n",
      "396/396 [==============================] - 0s - loss: 0.2314 - val_loss: 0.2657\n",
      "Epoch 117/500\n",
      "396/396 [==============================] - 0s - loss: 0.2311 - val_loss: 0.2785\n",
      "Epoch 118/500\n",
      "396/396 [==============================] - 0s - loss: 0.2312 - val_loss: 0.2713\n",
      "Epoch 119/500\n",
      "396/396 [==============================] - 0s - loss: 0.2311 - val_loss: 0.2732\n",
      "Epoch 120/500\n",
      "396/396 [==============================] - 0s - loss: 0.2271 - val_loss: 0.2732\n",
      "Epoch 121/500\n",
      "396/396 [==============================] - 0s - loss: 0.2292 - val_loss: 0.2730\n",
      "Epoch 122/500\n",
      "396/396 [==============================] - 0s - loss: 0.2305 - val_loss: 0.2860\n",
      "Epoch 123/500\n",
      "396/396 [==============================] - 0s - loss: 0.2305 - val_loss: 0.2636\n",
      "Epoch 124/500\n",
      "396/396 [==============================] - 0s - loss: 0.2319 - val_loss: 0.2970\n",
      "Epoch 125/500\n",
      "396/396 [==============================] - 0s - loss: 0.2314 - val_loss: 0.2598\n",
      "Epoch 126/500\n",
      "396/396 [==============================] - 0s - loss: 0.2339 - val_loss: 0.3018\n",
      "Epoch 127/500\n",
      "396/396 [==============================] - 0s - loss: 0.2333 - val_loss: 0.2642\n",
      "Epoch 128/500\n",
      "396/396 [==============================] - 0s - loss: 0.2300 - val_loss: 0.2833\n",
      "Epoch 129/500\n",
      "396/396 [==============================] - 0s - loss: 0.2289 - val_loss: 0.2695\n",
      "Epoch 130/500\n",
      "396/396 [==============================] - 0s - loss: 0.2289 - val_loss: 0.2847\n",
      "Epoch 131/500\n",
      "396/396 [==============================] - 0s - loss: 0.2301 - val_loss: 0.2685\n",
      "Epoch 132/500\n",
      "396/396 [==============================] - 0s - loss: 0.2283 - val_loss: 0.2894\n",
      "Epoch 133/500\n",
      "396/396 [==============================] - 0s - loss: 0.2312 - val_loss: 0.2677\n",
      "Epoch 134/500\n",
      "396/396 [==============================] - 0s - loss: 0.2294 - val_loss: 0.2894\n",
      "Epoch 135/500\n",
      "396/396 [==============================] - 0s - loss: 0.2276 - val_loss: 0.2658\n",
      "Epoch 136/500\n",
      "396/396 [==============================] - 0s - loss: 0.2297 - val_loss: 0.2954\n",
      "Epoch 137/500\n",
      "396/396 [==============================] - 0s - loss: 0.2302 - val_loss: 0.2653\n",
      "Epoch 138/500\n",
      "396/396 [==============================] - 0s - loss: 0.2302 - val_loss: 0.2927\n",
      "Epoch 139/500\n",
      "396/396 [==============================] - 0s - loss: 0.2303 - val_loss: 0.2656\n",
      "Epoch 140/500\n",
      "396/396 [==============================] - 0s - loss: 0.2310 - val_loss: 0.2968\n",
      "Epoch 141/500\n",
      "396/396 [==============================] - 0s - loss: 0.2315 - val_loss: 0.2668\n",
      "Epoch 142/500\n",
      "396/396 [==============================] - 0s - loss: 0.2303 - val_loss: 0.2851\n",
      "Epoch 143/500\n",
      "396/396 [==============================] - 0s - loss: 0.2304 - val_loss: 0.2724\n",
      "Epoch 144/500\n",
      "396/396 [==============================] - 0s - loss: 0.2282 - val_loss: 0.2850\n",
      "Epoch 145/500\n",
      "396/396 [==============================] - 0s - loss: 0.2279 - val_loss: 0.2694\n",
      "Epoch 146/500\n",
      "396/396 [==============================] - 0s - loss: 0.2298 - val_loss: 0.2925\n",
      "Epoch 147/500\n",
      "396/396 [==============================] - 0s - loss: 0.2280 - val_loss: 0.2694\n",
      "Epoch 148/500\n",
      "396/396 [==============================] - 0s - loss: 0.2290 - val_loss: 0.2938\n",
      "Epoch 149/500\n",
      "396/396 [==============================] - 0s - loss: 0.2276 - val_loss: 0.2683\n",
      "Epoch 150/500\n",
      "396/396 [==============================] - 0s - loss: 0.2306 - val_loss: 0.2921\n",
      "Epoch 151/500\n",
      "396/396 [==============================] - 0s - loss: 0.2292 - val_loss: 0.2680\n",
      "Epoch 152/500\n",
      "396/396 [==============================] - 0s - loss: 0.2272 - val_loss: 0.2895\n",
      "Epoch 153/500\n",
      "396/396 [==============================] - 0s - loss: 0.2282 - val_loss: 0.2659\n",
      "Epoch 154/500\n",
      "396/396 [==============================] - 0s - loss: 0.2270 - val_loss: 0.2869\n",
      "Epoch 155/500\n",
      "396/396 [==============================] - 0s - loss: 0.2280 - val_loss: 0.2739\n",
      "Epoch 156/500\n",
      "396/396 [==============================] - 0s - loss: 0.2286 - val_loss: 0.2875\n",
      "Epoch 157/500\n",
      "396/396 [==============================] - 0s - loss: 0.2287 - val_loss: 0.2686\n",
      "Epoch 158/500\n",
      "396/396 [==============================] - 0s - loss: 0.2264 - val_loss: 0.2910\n",
      "Epoch 159/500\n",
      "396/396 [==============================] - 0s - loss: 0.2287 - val_loss: 0.2683\n",
      "Epoch 160/500\n",
      "396/396 [==============================] - 0s - loss: 0.2286 - val_loss: 0.3034\n",
      "Epoch 161/500\n",
      "396/396 [==============================] - 0s - loss: 0.2290 - val_loss: 0.2663\n",
      "Epoch 162/500\n",
      "396/396 [==============================] - 0s - loss: 0.2262 - val_loss: 0.2970\n",
      "Epoch 163/500\n",
      "396/396 [==============================] - 0s - loss: 0.2282 - val_loss: 0.2727\n",
      "Epoch 164/500\n",
      "396/396 [==============================] - 0s - loss: 0.2282 - val_loss: 0.2846\n",
      "Epoch 165/500\n",
      "396/396 [==============================] - 0s - loss: 0.2253 - val_loss: 0.2743\n",
      "Epoch 166/500\n",
      "396/396 [==============================] - 0s - loss: 0.2271 - val_loss: 0.2843\n",
      "Epoch 167/500\n",
      "396/396 [==============================] - 0s - loss: 0.2276 - val_loss: 0.2797\n",
      "Epoch 168/500\n",
      "396/396 [==============================] - 0s - loss: 0.2263 - val_loss: 0.2822\n",
      "Epoch 169/500\n",
      "396/396 [==============================] - 0s - loss: 0.2283 - val_loss: 0.2782\n",
      "Epoch 170/500\n",
      "396/396 [==============================] - 0s - loss: 0.2260 - val_loss: 0.2847\n",
      "Epoch 171/500\n",
      "396/396 [==============================] - 0s - loss: 0.2261 - val_loss: 0.2770\n",
      "Epoch 172/500\n",
      "396/396 [==============================] - 0s - loss: 0.2289 - val_loss: 0.2895\n",
      "Epoch 173/500\n",
      "396/396 [==============================] - 0s - loss: 0.2314 - val_loss: 0.2922\n",
      "Epoch 174/500\n",
      "396/396 [==============================] - 0s - loss: 0.2285 - val_loss: 0.2732\n",
      "Epoch 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396/396 [==============================] - 0s - loss: 0.2278 - val_loss: 0.2967\n",
      "Epoch 176/500\n",
      "396/396 [==============================] - 0s - loss: 0.2271 - val_loss: 0.2681\n",
      "Epoch 177/500\n",
      "396/396 [==============================] - 0s - loss: 0.2296 - val_loss: 0.2995\n",
      "Epoch 178/500\n",
      "396/396 [==============================] - 0s - loss: 0.2270 - val_loss: 0.2698\n",
      "Epoch 179/500\n",
      "396/396 [==============================] - 0s - loss: 0.2278 - val_loss: 0.2937\n",
      "Epoch 180/500\n",
      "396/396 [==============================] - 0s - loss: 0.2269 - val_loss: 0.2724\n",
      "Epoch 181/500\n",
      "396/396 [==============================] - 0s - loss: 0.2285 - val_loss: 0.2939\n",
      "Epoch 182/500\n",
      "396/396 [==============================] - 0s - loss: 0.2262 - val_loss: 0.2755\n",
      "Epoch 183/500\n",
      "396/396 [==============================] - 0s - loss: 0.2250 - val_loss: 0.2886\n",
      "Epoch 184/500\n",
      "396/396 [==============================] - 0s - loss: 0.2248 - val_loss: 0.2742\n",
      "Epoch 185/500\n",
      "396/396 [==============================] - 0s - loss: 0.2254 - val_loss: 0.2855\n",
      "Epoch 186/500\n",
      "396/396 [==============================] - 0s - loss: 0.2255 - val_loss: 0.2680\n",
      "Epoch 187/500\n",
      "396/396 [==============================] - 0s - loss: 0.2249 - val_loss: 0.2858\n",
      "Epoch 188/500\n",
      "396/396 [==============================] - 0s - loss: 0.2246 - val_loss: 0.2706\n",
      "Epoch 189/500\n",
      "396/396 [==============================] - 0s - loss: 0.2233 - val_loss: 0.2990\n",
      "Epoch 190/500\n",
      "396/396 [==============================] - 0s - loss: 0.2258 - val_loss: 0.2641\n",
      "Epoch 191/500\n",
      "396/396 [==============================] - 0s - loss: 0.2261 - val_loss: 0.2995\n",
      "Epoch 192/500\n",
      "396/396 [==============================] - 0s - loss: 0.2261 - val_loss: 0.2676\n",
      "Epoch 193/500\n",
      "396/396 [==============================] - 0s - loss: 0.2248 - val_loss: 0.2877\n",
      "Epoch 194/500\n",
      "396/396 [==============================] - 0s - loss: 0.2233 - val_loss: 0.2734\n",
      "Epoch 195/500\n",
      "396/396 [==============================] - 0s - loss: 0.2238 - val_loss: 0.2896\n",
      "Epoch 196/500\n",
      "396/396 [==============================] - 0s - loss: 0.2260 - val_loss: 0.2821\n",
      "Epoch 197/500\n",
      "396/396 [==============================] - 0s - loss: 0.2265 - val_loss: 0.2860\n",
      "Epoch 198/500\n",
      "396/396 [==============================] - 0s - loss: 0.2261 - val_loss: 0.2772\n",
      "Epoch 199/500\n",
      "396/396 [==============================] - 0s - loss: 0.2255 - val_loss: 0.2852\n",
      "Epoch 200/500\n",
      "396/396 [==============================] - 0s - loss: 0.2241 - val_loss: 0.2788\n",
      "Epoch 201/500\n",
      "396/396 [==============================] - 0s - loss: 0.2243 - val_loss: 0.2884\n",
      "Epoch 202/500\n",
      "396/396 [==============================] - 0s - loss: 0.2261 - val_loss: 0.2691\n",
      "Epoch 203/500\n",
      "396/396 [==============================] - 0s - loss: 0.2242 - val_loss: 0.2962\n",
      "Epoch 204/500\n",
      "396/396 [==============================] - 0s - loss: 0.2240 - val_loss: 0.2670\n",
      "Epoch 205/500\n",
      "396/396 [==============================] - 0s - loss: 0.2226 - val_loss: 0.2947\n",
      "Epoch 206/500\n",
      "396/396 [==============================] - 0s - loss: 0.2238 - val_loss: 0.2654\n",
      "Epoch 207/500\n",
      "396/396 [==============================] - 0s - loss: 0.2272 - val_loss: 0.3015\n",
      "Epoch 208/500\n",
      "396/396 [==============================] - 0s - loss: 0.2243 - val_loss: 0.2747\n",
      "Epoch 209/500\n",
      "396/396 [==============================] - 0s - loss: 0.2239 - val_loss: 0.2910\n",
      "Epoch 210/500\n",
      "396/396 [==============================] - 0s - loss: 0.2234 - val_loss: 0.2784\n",
      "Epoch 211/500\n",
      "396/396 [==============================] - 0s - loss: 0.2219 - val_loss: 0.2819\n",
      "Epoch 212/500\n",
      "396/396 [==============================] - 0s - loss: 0.2211 - val_loss: 0.2819\n",
      "Epoch 213/500\n",
      "396/396 [==============================] - 0s - loss: 0.2206 - val_loss: 0.2842\n",
      "Epoch 214/500\n",
      "396/396 [==============================] - 0s - loss: 0.2236 - val_loss: 0.2873\n",
      "Epoch 215/500\n",
      "396/396 [==============================] - 0s - loss: 0.2255 - val_loss: 0.2801\n",
      "Epoch 216/500\n",
      "396/396 [==============================] - 0s - loss: 0.2275 - val_loss: 0.2788\n",
      "Epoch 217/500\n",
      "396/396 [==============================] - 0s - loss: 0.2224 - val_loss: 0.2848\n",
      "Epoch 218/500\n",
      "396/396 [==============================] - 0s - loss: 0.2227 - val_loss: 0.2759\n",
      "Epoch 219/500\n",
      "396/396 [==============================] - 0s - loss: 0.2230 - val_loss: 0.2838\n",
      "Epoch 220/500\n",
      "396/396 [==============================] - 0s - loss: 0.2223 - val_loss: 0.2752\n",
      "Epoch 221/500\n",
      "396/396 [==============================] - 0s - loss: 0.2213 - val_loss: 0.2858\n",
      "Epoch 222/500\n",
      "396/396 [==============================] - 0s - loss: 0.2230 - val_loss: 0.2729\n",
      "Epoch 223/500\n",
      "396/396 [==============================] - 0s - loss: 0.2227 - val_loss: 0.2988\n",
      "Epoch 224/500\n",
      "396/396 [==============================] - 0s - loss: 0.2232 - val_loss: 0.2614\n",
      "Epoch 225/500\n",
      "396/396 [==============================] - 0s - loss: 0.2237 - val_loss: 0.3065\n",
      "Epoch 226/500\n",
      "396/396 [==============================] - 0s - loss: 0.2242 - val_loss: 0.2677\n",
      "Epoch 227/500\n",
      "396/396 [==============================] - 0s - loss: 0.2241 - val_loss: 0.2923\n",
      "Epoch 228/500\n",
      "396/396 [==============================] - 0s - loss: 0.2224 - val_loss: 0.2781\n",
      "Epoch 229/500\n",
      "396/396 [==============================] - 0s - loss: 0.2189 - val_loss: 0.2839\n",
      "Epoch 230/500\n",
      "396/396 [==============================] - 0s - loss: 0.2198 - val_loss: 0.2791\n",
      "Epoch 231/500\n",
      "396/396 [==============================] - 0s - loss: 0.2206 - val_loss: 0.2773\n",
      "Epoch 232/500\n",
      "396/396 [==============================] - 0s - loss: 0.2233 - val_loss: 0.2820\n",
      "Epoch 233/500\n",
      "396/396 [==============================] - 0s - loss: 0.2239 - val_loss: 0.2693\n",
      "Epoch 234/500\n",
      "396/396 [==============================] - 0s - loss: 0.2197 - val_loss: 0.2910\n",
      "Epoch 235/500\n",
      "396/396 [==============================] - 0s - loss: 0.2219 - val_loss: 0.2748\n",
      "Epoch 236/500\n",
      "396/396 [==============================] - 0s - loss: 0.2200 - val_loss: 0.2795\n",
      "Epoch 237/500\n",
      "396/396 [==============================] - 0s - loss: 0.2197 - val_loss: 0.2714\n",
      "Epoch 238/500\n",
      "396/396 [==============================] - 0s - loss: 0.2185 - val_loss: 0.2800\n",
      "Epoch 239/500\n",
      "396/396 [==============================] - 0s - loss: 0.2202 - val_loss: 0.2692\n",
      "Epoch 240/500\n",
      "396/396 [==============================] - 0s - loss: 0.2204 - val_loss: 0.3003\n",
      "Epoch 241/500\n",
      "396/396 [==============================] - 0s - loss: 0.2227 - val_loss: 0.2658\n",
      "Epoch 242/500\n",
      "396/396 [==============================] - 0s - loss: 0.2221 - val_loss: 0.2971\n",
      "Epoch 243/500\n",
      "396/396 [==============================] - 0s - loss: 0.2232 - val_loss: 0.2703\n",
      "Epoch 244/500\n",
      "396/396 [==============================] - 0s - loss: 0.2232 - val_loss: 0.2878\n",
      "Epoch 245/500\n",
      "396/396 [==============================] - 0s - loss: 0.2200 - val_loss: 0.2670\n",
      "Epoch 246/500\n",
      "396/396 [==============================] - 0s - loss: 0.2196 - val_loss: 0.2924\n",
      "Epoch 247/500\n",
      "396/396 [==============================] - 0s - loss: 0.2232 - val_loss: 0.2711\n",
      "Epoch 248/500\n",
      "396/396 [==============================] - 0s - loss: 0.2203 - val_loss: 0.2798\n",
      "Epoch 249/500\n",
      "396/396 [==============================] - 0s - loss: 0.2205 - val_loss: 0.2719\n",
      "Epoch 250/500\n",
      "396/396 [==============================] - 0s - loss: 0.2211 - val_loss: 0.2728\n",
      "Epoch 251/500\n",
      "396/396 [==============================] - 0s - loss: 0.2199 - val_loss: 0.2819\n",
      "Epoch 252/500\n",
      "396/396 [==============================] - 0s - loss: 0.2187 - val_loss: 0.2667\n",
      "Epoch 253/500\n",
      "396/396 [==============================] - 0s - loss: 0.2208 - val_loss: 0.2805\n",
      "Epoch 254/500\n",
      "396/396 [==============================] - 0s - loss: 0.2187 - val_loss: 0.2698\n",
      "Epoch 255/500\n",
      "396/396 [==============================] - 0s - loss: 0.2210 - val_loss: 0.2961\n",
      "Epoch 256/500\n",
      "396/396 [==============================] - 0s - loss: 0.2223 - val_loss: 0.2621\n",
      "Epoch 257/500\n",
      "396/396 [==============================] - 0s - loss: 0.2175 - val_loss: 0.2858\n",
      "Epoch 258/500\n",
      "396/396 [==============================] - 0s - loss: 0.2196 - val_loss: 0.2673\n",
      "Epoch 259/500\n",
      "396/396 [==============================] - 0s - loss: 0.2202 - val_loss: 0.2852\n",
      "Epoch 260/500\n",
      "396/396 [==============================] - 0s - loss: 0.2195 - val_loss: 0.2698\n",
      "Epoch 261/500\n",
      "396/396 [==============================] - 0s - loss: 0.2173 - val_loss: 0.2788\n",
      "Epoch 262/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396/396 [==============================] - 0s - loss: 0.2202 - val_loss: 0.2693\n",
      "Epoch 263/500\n",
      "396/396 [==============================] - 0s - loss: 0.2180 - val_loss: 0.2813\n",
      "Epoch 264/500\n",
      "396/396 [==============================] - 0s - loss: 0.2193 - val_loss: 0.2638\n",
      "Epoch 265/500\n",
      "396/396 [==============================] - 0s - loss: 0.2194 - val_loss: 0.2985\n",
      "Epoch 266/500\n",
      "396/396 [==============================] - 0s - loss: 0.2213 - val_loss: 0.2551\n",
      "Epoch 267/500\n",
      "396/396 [==============================] - 0s - loss: 0.2181 - val_loss: 0.2900\n",
      "Epoch 268/500\n",
      "396/396 [==============================] - 0s - loss: 0.2173 - val_loss: 0.2636\n",
      "Epoch 269/500\n",
      "396/396 [==============================] - 0s - loss: 0.2157 - val_loss: 0.2674\n",
      "Epoch 270/500\n",
      "396/396 [==============================] - 0s - loss: 0.2153 - val_loss: 0.2656\n",
      "Epoch 271/500\n",
      "396/396 [==============================] - 0s - loss: 0.2160 - val_loss: 0.2667\n",
      "Epoch 272/500\n",
      "396/396 [==============================] - 0s - loss: 0.2173 - val_loss: 0.2687\n",
      "Epoch 273/500\n",
      "396/396 [==============================] - 0s - loss: 0.2196 - val_loss: 0.2649\n",
      "Epoch 274/500\n",
      "396/396 [==============================] - 0s - loss: 0.2185 - val_loss: 0.2979\n",
      "Epoch 275/500\n",
      "396/396 [==============================] - 0s - loss: 0.2226 - val_loss: 0.2620\n",
      "Epoch 276/500\n",
      "396/396 [==============================] - 0s - loss: 0.2174 - val_loss: 0.2745\n",
      "Epoch 277/500\n",
      "396/396 [==============================] - 0s - loss: 0.2146 - val_loss: 0.2609\n",
      "Epoch 278/500\n",
      "396/396 [==============================] - 0s - loss: 0.2153 - val_loss: 0.2665\n",
      "Epoch 279/500\n",
      "396/396 [==============================] - 0s - loss: 0.2116 - val_loss: 0.2688\n",
      "Epoch 280/500\n",
      "396/396 [==============================] - 0s - loss: 0.2152 - val_loss: 0.2788\n",
      "Epoch 281/500\n",
      "396/396 [==============================] - 0s - loss: 0.2156 - val_loss: 0.2695\n",
      "Epoch 282/500\n",
      "396/396 [==============================] - 0s - loss: 0.2150 - val_loss: 0.2751\n",
      "Epoch 283/500\n",
      "396/396 [==============================] - 0s - loss: 0.2160 - val_loss: 0.2637\n",
      "Epoch 284/500\n",
      "396/396 [==============================] - 0s - loss: 0.2189 - val_loss: 0.2880\n",
      "Epoch 285/500\n",
      "396/396 [==============================] - 0s - loss: 0.2209 - val_loss: 0.2616\n",
      "Epoch 286/500\n",
      "396/396 [==============================] - 0s - loss: 0.2178 - val_loss: 0.2866\n",
      "Epoch 287/500\n",
      "396/396 [==============================] - 0s - loss: 0.2149 - val_loss: 0.2605\n",
      "Epoch 288/500\n",
      "396/396 [==============================] - 0s - loss: 0.2143 - val_loss: 0.2800\n",
      "Epoch 289/500\n",
      "396/396 [==============================] - 0s - loss: 0.2151 - val_loss: 0.2593\n",
      "Epoch 290/500\n",
      "396/396 [==============================] - 0s - loss: 0.2145 - val_loss: 0.2765\n",
      "Epoch 291/500\n",
      "396/396 [==============================] - 0s - loss: 0.2138 - val_loss: 0.2578\n",
      "Epoch 292/500\n",
      "396/396 [==============================] - 0s - loss: 0.2140 - val_loss: 0.2775\n",
      "Epoch 293/500\n",
      "396/396 [==============================] - 0s - loss: 0.2169 - val_loss: 0.2622\n",
      "Epoch 294/500\n",
      "396/396 [==============================] - 0s - loss: 0.2153 - val_loss: 0.2824\n",
      "Epoch 295/500\n",
      "396/396 [==============================] - 0s - loss: 0.2165 - val_loss: 0.2627\n",
      "Epoch 296/500\n",
      "396/396 [==============================] - 0s - loss: 0.2140 - val_loss: 0.2748\n",
      "Epoch 297/500\n",
      "396/396 [==============================] - 0s - loss: 0.2146 - val_loss: 0.2634\n",
      "Epoch 298/500\n",
      "396/396 [==============================] - 0s - loss: 0.2133 - val_loss: 0.2716\n",
      "Epoch 299/500\n",
      "396/396 [==============================] - 0s - loss: 0.2142 - val_loss: 0.2733\n",
      "Epoch 300/500\n",
      "396/396 [==============================] - 0s - loss: 0.2095 - val_loss: 0.2665\n",
      "Epoch 301/500\n",
      "396/396 [==============================] - 0s - loss: 0.2115 - val_loss: 0.2658\n",
      "Epoch 302/500\n",
      "396/396 [==============================] - 0s - loss: 0.2117 - val_loss: 0.2698\n",
      "Epoch 303/500\n",
      "396/396 [==============================] - 0s - loss: 0.2081 - val_loss: 0.2642\n",
      "Epoch 304/500\n",
      "396/396 [==============================] - 0s - loss: 0.2148 - val_loss: 0.3069\n",
      "Epoch 305/500\n",
      "396/396 [==============================] - 0s - loss: 0.2226 - val_loss: 0.2602\n",
      "Epoch 306/500\n",
      "396/396 [==============================] - 0s - loss: 0.2115 - val_loss: 0.2761\n",
      "Epoch 307/500\n",
      "396/396 [==============================] - 0s - loss: 0.2109 - val_loss: 0.2583\n",
      "Epoch 308/500\n",
      "396/396 [==============================] - 0s - loss: 0.2106 - val_loss: 0.2839\n",
      "Epoch 309/500\n",
      "396/396 [==============================] - 0s - loss: 0.2137 - val_loss: 0.2610\n",
      "Epoch 310/500\n",
      "396/396 [==============================] - 0s - loss: 0.2112 - val_loss: 0.2683\n",
      "Epoch 311/500\n",
      "396/396 [==============================] - 0s - loss: 0.2100 - val_loss: 0.2662\n",
      "Epoch 312/500\n",
      "396/396 [==============================] - 0s - loss: 0.2091 - val_loss: 0.2694\n",
      "Epoch 313/500\n",
      "396/396 [==============================] - 0s - loss: 0.2092 - val_loss: 0.2588\n",
      "Epoch 314/500\n",
      "396/396 [==============================] - 0s - loss: 0.2102 - val_loss: 0.2714\n",
      "Epoch 315/500\n",
      "396/396 [==============================] - 0s - loss: 0.2094 - val_loss: 0.2629\n",
      "Epoch 316/500\n",
      "396/396 [==============================] - 0s - loss: 0.2109 - val_loss: 0.2782\n",
      "Epoch 317/500\n",
      "396/396 [==============================] - 0s - loss: 0.2126 - val_loss: 0.2677\n",
      "Epoch 318/500\n",
      "396/396 [==============================] - 0s - loss: 0.2125 - val_loss: 0.2806\n",
      "Epoch 319/500\n",
      "396/396 [==============================] - 0s - loss: 0.2135 - val_loss: 0.2645\n",
      "Epoch 320/500\n",
      "396/396 [==============================] - 0s - loss: 0.2109 - val_loss: 0.2888\n",
      "Epoch 321/500\n",
      "396/396 [==============================] - 0s - loss: 0.2122 - val_loss: 0.2580\n",
      "Epoch 322/500\n",
      "396/396 [==============================] - 0s - loss: 0.2094 - val_loss: 0.2748\n",
      "Epoch 323/500\n",
      "396/396 [==============================] - 0s - loss: 0.2096 - val_loss: 0.2648\n",
      "Epoch 324/500\n",
      "396/396 [==============================] - 0s - loss: 0.2112 - val_loss: 0.2787\n",
      "Epoch 325/500\n",
      "396/396 [==============================] - 0s - loss: 0.2105 - val_loss: 0.2672\n",
      "Epoch 326/500\n",
      "396/396 [==============================] - 0s - loss: 0.2099 - val_loss: 0.2736\n",
      "Epoch 327/500\n",
      "396/396 [==============================] - 0s - loss: 0.2100 - val_loss: 0.2682\n",
      "Epoch 328/500\n",
      "396/396 [==============================] - 0s - loss: 0.2054 - val_loss: 0.2801\n",
      "Epoch 329/500\n",
      "396/396 [==============================] - 0s - loss: 0.2080 - val_loss: 0.2647\n",
      "Epoch 330/500\n",
      "396/396 [==============================] - 0s - loss: 0.2091 - val_loss: 0.2861\n",
      "Epoch 331/500\n",
      "396/396 [==============================] - 0s - loss: 0.2080 - val_loss: 0.2619\n",
      "Epoch 332/500\n",
      "396/396 [==============================] - 0s - loss: 0.2093 - val_loss: 0.2898\n",
      "Epoch 333/500\n",
      "396/396 [==============================] - 0s - loss: 0.2074 - val_loss: 0.2790\n",
      "Epoch 334/500\n",
      "396/396 [==============================] - 0s - loss: 0.2090 - val_loss: 0.2816\n",
      "Epoch 335/500\n",
      "396/396 [==============================] - 0s - loss: 0.2067 - val_loss: 0.2730\n",
      "Epoch 336/500\n",
      "396/396 [==============================] - 0s - loss: 0.2043 - val_loss: 0.2749\n",
      "Epoch 337/500\n",
      "396/396 [==============================] - 0s - loss: 0.2066 - val_loss: 0.2796\n",
      "Epoch 338/500\n",
      "396/396 [==============================] - 0s - loss: 0.2103 - val_loss: 0.2794\n",
      "Epoch 339/500\n",
      "396/396 [==============================] - 0s - loss: 0.2080 - val_loss: 0.2785\n",
      "Epoch 340/500\n",
      "396/396 [==============================] - 0s - loss: 0.2092 - val_loss: 0.2715\n",
      "Epoch 341/500\n",
      "396/396 [==============================] - 0s - loss: 0.2075 - val_loss: 0.2748\n",
      "Epoch 342/500\n",
      "396/396 [==============================] - 0s - loss: 0.2033 - val_loss: 0.2805\n",
      "Epoch 343/500\n",
      "396/396 [==============================] - 0s - loss: 0.2052 - val_loss: 0.2751\n",
      "Epoch 344/500\n",
      "396/396 [==============================] - 0s - loss: 0.2080 - val_loss: 0.2839\n",
      "Epoch 345/500\n",
      "396/396 [==============================] - 0s - loss: 0.2072 - val_loss: 0.2862\n",
      "Epoch 346/500\n",
      "396/396 [==============================] - 0s - loss: 0.2041 - val_loss: 0.2807\n",
      "Epoch 347/500\n",
      "396/396 [==============================] - 0s - loss: 0.2024 - val_loss: 0.2804\n",
      "Epoch 348/500\n",
      "396/396 [==============================] - 0s - loss: 0.2048 - val_loss: 0.2772\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396/396 [==============================] - 0s - loss: 0.2046 - val_loss: 0.2816\n",
      "Epoch 350/500\n",
      "396/396 [==============================] - 0s - loss: 0.2045 - val_loss: 0.2794\n",
      "Epoch 351/500\n",
      "396/396 [==============================] - 0s - loss: 0.2033 - val_loss: 0.2840\n",
      "Epoch 352/500\n",
      "396/396 [==============================] - 0s - loss: 0.2039 - val_loss: 0.2863\n",
      "Epoch 353/500\n",
      "396/396 [==============================] - 0s - loss: 0.2052 - val_loss: 0.2834\n",
      "Epoch 354/500\n",
      "396/396 [==============================] - 0s - loss: 0.2028 - val_loss: 0.3009\n",
      "Epoch 355/500\n",
      "396/396 [==============================] - 0s - loss: 0.2081 - val_loss: 0.2802\n",
      "Epoch 356/500\n",
      "396/396 [==============================] - 0s - loss: 0.2049 - val_loss: 0.2944\n",
      "Epoch 357/500\n",
      "396/396 [==============================] - 0s - loss: 0.2063 - val_loss: 0.2846\n",
      "Epoch 358/500\n",
      "396/396 [==============================] - 0s - loss: 0.2076 - val_loss: 0.2909\n",
      "Epoch 359/500\n",
      "396/396 [==============================] - 0s - loss: 0.2076 - val_loss: 0.2804\n",
      "Epoch 360/500\n",
      "396/396 [==============================] - 0s - loss: 0.2054 - val_loss: 0.2871\n",
      "Epoch 361/500\n",
      "396/396 [==============================] - 0s - loss: 0.2056 - val_loss: 0.2753\n",
      "Epoch 362/500\n",
      "396/396 [==============================] - 0s - loss: 0.2006 - val_loss: 0.3076\n",
      "Epoch 363/500\n",
      "396/396 [==============================] - 0s - loss: 0.2071 - val_loss: 0.2783\n",
      "Epoch 364/500\n",
      "396/396 [==============================] - 0s - loss: 0.2029 - val_loss: 0.3062\n",
      "Epoch 365/500\n",
      "396/396 [==============================] - 0s - loss: 0.2022 - val_loss: 0.2767\n",
      "Epoch 366/500\n",
      "396/396 [==============================] - 0s - loss: 0.2030 - val_loss: 0.2883\n",
      "Epoch 367/500\n",
      "396/396 [==============================] - 0s - loss: 0.2005 - val_loss: 0.2774\n",
      "Epoch 368/500\n",
      "396/396 [==============================] - 0s - loss: 0.2035 - val_loss: 0.3012\n",
      "Epoch 369/500\n",
      "396/396 [==============================] - 0s - loss: 0.2044 - val_loss: 0.2862\n",
      "Epoch 370/500\n",
      "396/396 [==============================] - 0s - loss: 0.2026 - val_loss: 0.3020\n",
      "Epoch 371/500\n",
      "396/396 [==============================] - 0s - loss: 0.2026 - val_loss: 0.2815\n",
      "Epoch 372/500\n",
      "396/396 [==============================] - 0s - loss: 0.2023 - val_loss: 0.2934\n",
      "Epoch 373/500\n",
      "396/396 [==============================] - 0s - loss: 0.2026 - val_loss: 0.2836\n",
      "Epoch 374/500\n",
      "396/396 [==============================] - 0s - loss: 0.2021 - val_loss: 0.2911\n",
      "Epoch 375/500\n",
      "396/396 [==============================] - 0s - loss: 0.2012 - val_loss: 0.2957\n",
      "Epoch 376/500\n",
      "396/396 [==============================] - 0s - loss: 0.2016 - val_loss: 0.2806\n",
      "Epoch 377/500\n",
      "396/396 [==============================] - 0s - loss: 0.2030 - val_loss: 0.3138\n",
      "Epoch 378/500\n",
      "396/396 [==============================] - 0s - loss: 0.2074 - val_loss: 0.2837\n",
      "Epoch 379/500\n",
      "396/396 [==============================] - 0s - loss: 0.2017 - val_loss: 0.2991\n",
      "Epoch 380/500\n",
      "396/396 [==============================] - 0s - loss: 0.2038 - val_loss: 0.2851\n",
      "Epoch 381/500\n",
      "396/396 [==============================] - 0s - loss: 0.2053 - val_loss: 0.3088\n",
      "Epoch 382/500\n",
      "396/396 [==============================] - 0s - loss: 0.2016 - val_loss: 0.2788\n",
      "Epoch 383/500\n",
      "396/396 [==============================] - 0s - loss: 0.2004 - val_loss: 0.2924\n",
      "Epoch 384/500\n",
      "396/396 [==============================] - 0s - loss: 0.2001 - val_loss: 0.3045\n",
      "Epoch 385/500\n",
      "396/396 [==============================] - 0s - loss: 0.2000 - val_loss: 0.2856\n",
      "Epoch 386/500\n",
      "396/396 [==============================] - 0s - loss: 0.2043 - val_loss: 0.3189\n",
      "Epoch 387/500\n",
      "396/396 [==============================] - 0s - loss: 0.2060 - val_loss: 0.2908\n",
      "Epoch 388/500\n",
      "396/396 [==============================] - 0s - loss: 0.2008 - val_loss: 0.3073\n",
      "Epoch 389/500\n",
      "396/396 [==============================] - 0s - loss: 0.2000 - val_loss: 0.2965\n",
      "Epoch 390/500\n",
      "396/396 [==============================] - 0s - loss: 0.1994 - val_loss: 0.3236\n",
      "Epoch 391/500\n",
      "396/396 [==============================] - 0s - loss: 0.2025 - val_loss: 0.2893\n",
      "Epoch 392/500\n",
      "396/396 [==============================] - 0s - loss: 0.2032 - val_loss: 0.3103\n",
      "Epoch 393/500\n",
      "396/396 [==============================] - 0s - loss: 0.2016 - val_loss: 0.2986\n",
      "Epoch 394/500\n",
      "396/396 [==============================] - 0s - loss: 0.2014 - val_loss: 0.3070\n",
      "Epoch 395/500\n",
      "396/396 [==============================] - 0s - loss: 0.1979 - val_loss: 0.2955\n",
      "Epoch 396/500\n",
      "396/396 [==============================] - 0s - loss: 0.2006 - val_loss: 0.2979\n",
      "Epoch 397/500\n",
      "396/396 [==============================] - 0s - loss: 0.1989 - val_loss: 0.2964\n",
      "Epoch 398/500\n",
      "396/396 [==============================] - 0s - loss: 0.2012 - val_loss: 0.3163\n",
      "Epoch 399/500\n",
      "396/396 [==============================] - 0s - loss: 0.2019 - val_loss: 0.2910\n",
      "Epoch 400/500\n",
      "396/396 [==============================] - 0s - loss: 0.2001 - val_loss: 0.3336\n",
      "Epoch 401/500\n",
      "396/396 [==============================] - 0s - loss: 0.2000 - val_loss: 0.2951\n",
      "Epoch 402/500\n",
      "396/396 [==============================] - 0s - loss: 0.1993 - val_loss: 0.3076\n",
      "Epoch 403/500\n",
      "396/396 [==============================] - 0s - loss: 0.1991 - val_loss: 0.2981\n",
      "Epoch 404/500\n",
      "396/396 [==============================] - 0s - loss: 0.1973 - val_loss: 0.3059\n",
      "Epoch 405/500\n",
      "396/396 [==============================] - 0s - loss: 0.1999 - val_loss: 0.3042\n",
      "Epoch 406/500\n",
      "396/396 [==============================] - 0s - loss: 0.2006 - val_loss: 0.3156\n",
      "Epoch 407/500\n",
      "396/396 [==============================] - 0s - loss: 0.1999 - val_loss: 0.3061\n",
      "Epoch 408/500\n",
      "396/396 [==============================] - 0s - loss: 0.2009 - val_loss: 0.3231\n",
      "Epoch 409/500\n",
      "396/396 [==============================] - 0s - loss: 0.1991 - val_loss: 0.3017\n",
      "Epoch 410/500\n",
      "396/396 [==============================] - 0s - loss: 0.2028 - val_loss: 0.3295\n",
      "Epoch 411/500\n",
      "396/396 [==============================] - 0s - loss: 0.2021 - val_loss: 0.3038\n",
      "Epoch 412/500\n",
      "396/396 [==============================] - 0s - loss: 0.1977 - val_loss: 0.3029\n",
      "Epoch 413/500\n",
      "396/396 [==============================] - 0s - loss: 0.1975 - val_loss: 0.3230\n",
      "Epoch 414/500\n",
      "396/396 [==============================] - 0s - loss: 0.1990 - val_loss: 0.2923\n",
      "Epoch 415/500\n",
      "396/396 [==============================] - 0s - loss: 0.1960 - val_loss: 0.3153\n",
      "Epoch 416/500\n",
      "396/396 [==============================] - 0s - loss: 0.1972 - val_loss: 0.3011\n",
      "Epoch 417/500\n",
      "396/396 [==============================] - 0s - loss: 0.1976 - val_loss: 0.3096\n",
      "Epoch 418/500\n",
      "396/396 [==============================] - 0s - loss: 0.2000 - val_loss: 0.3378\n",
      "Epoch 419/500\n",
      "396/396 [==============================] - 0s - loss: 0.1995 - val_loss: 0.2985\n",
      "Epoch 420/500\n",
      "396/396 [==============================] - 0s - loss: 0.1997 - val_loss: 0.3367\n",
      "Epoch 421/500\n",
      "396/396 [==============================] - 0s - loss: 0.2022 - val_loss: 0.3234\n",
      "Epoch 422/500\n",
      "396/396 [==============================] - 0s - loss: 0.2010 - val_loss: 0.3100\n",
      "Epoch 423/500\n",
      "396/396 [==============================] - 0s - loss: 0.1993 - val_loss: 0.3097\n",
      "Epoch 424/500\n",
      "396/396 [==============================] - 0s - loss: 0.1944 - val_loss: 0.3099\n",
      "Epoch 425/500\n",
      "396/396 [==============================] - 0s - loss: 0.1943 - val_loss: 0.3219\n",
      "Epoch 426/500\n",
      "396/396 [==============================] - 0s - loss: 0.1970 - val_loss: 0.2984\n",
      "Epoch 427/500\n",
      "396/396 [==============================] - 0s - loss: 0.1956 - val_loss: 0.3329\n",
      "Epoch 428/500\n",
      "396/396 [==============================] - 0s - loss: 0.1972 - val_loss: 0.2946\n",
      "Epoch 429/500\n",
      "396/396 [==============================] - 0s - loss: 0.1997 - val_loss: 0.3528\n",
      "Epoch 430/500\n",
      "396/396 [==============================] - 0s - loss: 0.2019 - val_loss: 0.2954\n",
      "Epoch 431/500\n",
      "396/396 [==============================] - 0s - loss: 0.1962 - val_loss: 0.3183\n",
      "Epoch 432/500\n",
      "396/396 [==============================] - 0s - loss: 0.1953 - val_loss: 0.3116\n",
      "Epoch 433/500\n",
      "396/396 [==============================] - 0s - loss: 0.1936 - val_loss: 0.3340\n",
      "Epoch 434/500\n",
      "396/396 [==============================] - 0s - loss: 0.1969 - val_loss: 0.3147\n",
      "Epoch 435/500\n",
      "396/396 [==============================] - 0s - loss: 0.1998 - val_loss: 0.3236\n",
      "Epoch 436/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396/396 [==============================] - 0s - loss: 0.1959 - val_loss: 0.3196\n",
      "Epoch 437/500\n",
      "396/396 [==============================] - 0s - loss: 0.1965 - val_loss: 0.3214\n",
      "Epoch 438/500\n",
      "396/396 [==============================] - 0s - loss: 0.1970 - val_loss: 0.3271\n",
      "Epoch 439/500\n",
      "396/396 [==============================] - 0s - loss: 0.1934 - val_loss: 0.3330\n",
      "Epoch 440/500\n",
      "396/396 [==============================] - 0s - loss: 0.2015 - val_loss: 0.3209\n",
      "Epoch 441/500\n",
      "396/396 [==============================] - 0s - loss: 0.1993 - val_loss: 0.3599\n",
      "Epoch 442/500\n",
      "396/396 [==============================] - 0s - loss: 0.2054 - val_loss: 0.3134\n",
      "Epoch 443/500\n",
      "396/396 [==============================] - 0s - loss: 0.1942 - val_loss: 0.3221\n",
      "Epoch 444/500\n",
      "396/396 [==============================] - 0s - loss: 0.1965 - val_loss: 0.3115\n",
      "Epoch 445/500\n",
      "396/396 [==============================] - 0s - loss: 0.1968 - val_loss: 0.3195\n",
      "Epoch 446/500\n",
      "396/396 [==============================] - 0s - loss: 0.1945 - val_loss: 0.3257\n",
      "Epoch 447/500\n",
      "396/396 [==============================] - 0s - loss: 0.1925 - val_loss: 0.3179\n",
      "Epoch 448/500\n",
      "396/396 [==============================] - 0s - loss: 0.1938 - val_loss: 0.3185\n",
      "Epoch 449/500\n",
      "396/396 [==============================] - 0s - loss: 0.1938 - val_loss: 0.3099\n",
      "Epoch 450/500\n",
      "396/396 [==============================] - 0s - loss: 0.1980 - val_loss: 0.3215\n",
      "Epoch 451/500\n",
      "396/396 [==============================] - 0s - loss: 0.1925 - val_loss: 0.3376\n",
      "Epoch 452/500\n",
      "396/396 [==============================] - 0s - loss: 0.1943 - val_loss: 0.3140\n",
      "Epoch 453/500\n",
      "396/396 [==============================] - 0s - loss: 0.1952 - val_loss: 0.3366\n",
      "Epoch 454/500\n",
      "396/396 [==============================] - 0s - loss: 0.1970 - val_loss: 0.3051\n",
      "Epoch 455/500\n",
      "396/396 [==============================] - 0s - loss: 0.1967 - val_loss: 0.3299\n",
      "Epoch 456/500\n",
      "396/396 [==============================] - 0s - loss: 0.1932 - val_loss: 0.2963\n",
      "Epoch 457/500\n",
      "396/396 [==============================] - 0s - loss: 0.1956 - val_loss: 0.3658\n",
      "Epoch 458/500\n",
      "396/396 [==============================] - 0s - loss: 0.1998 - val_loss: 0.2999\n",
      "Epoch 459/500\n",
      "396/396 [==============================] - 0s - loss: 0.1964 - val_loss: 0.3470\n",
      "Epoch 460/500\n",
      "396/396 [==============================] - 0s - loss: 0.1951 - val_loss: 0.3037\n",
      "Epoch 461/500\n",
      "396/396 [==============================] - 0s - loss: 0.1949 - val_loss: 0.3297\n",
      "Epoch 462/500\n",
      "396/396 [==============================] - 0s - loss: 0.1946 - val_loss: 0.3301\n",
      "Epoch 463/500\n",
      "396/396 [==============================] - 0s - loss: 0.1905 - val_loss: 0.3352\n",
      "Epoch 464/500\n",
      "396/396 [==============================] - 0s - loss: 0.1928 - val_loss: 0.3389\n",
      "Epoch 465/500\n",
      "396/396 [==============================] - 0s - loss: 0.1958 - val_loss: 0.3136\n",
      "Epoch 466/500\n",
      "396/396 [==============================] - 0s - loss: 0.1944 - val_loss: 0.3355\n",
      "Epoch 467/500\n",
      "396/396 [==============================] - 0s - loss: 0.1918 - val_loss: 0.3153\n",
      "Epoch 468/500\n",
      "396/396 [==============================] - 0s - loss: 0.1961 - val_loss: 0.3401\n",
      "Epoch 469/500\n",
      "396/396 [==============================] - 0s - loss: 0.1958 - val_loss: 0.3241\n",
      "Epoch 470/500\n",
      "396/396 [==============================] - 0s - loss: 0.1904 - val_loss: 0.3346\n",
      "Epoch 471/500\n",
      "396/396 [==============================] - 0s - loss: 0.1971 - val_loss: 0.3504\n",
      "Epoch 472/500\n",
      "396/396 [==============================] - 0s - loss: 0.1936 - val_loss: 0.3262\n",
      "Epoch 473/500\n",
      "396/396 [==============================] - 0s - loss: 0.1929 - val_loss: 0.3236\n",
      "Epoch 474/500\n",
      "396/396 [==============================] - 0s - loss: 0.1931 - val_loss: 0.3468\n",
      "Epoch 475/500\n",
      "396/396 [==============================] - 0s - loss: 0.1925 - val_loss: 0.3099\n",
      "Epoch 476/500\n",
      "396/396 [==============================] - 0s - loss: 0.1958 - val_loss: 0.3380\n",
      "Epoch 477/500\n",
      "396/396 [==============================] - 0s - loss: 0.1942 - val_loss: 0.3177\n",
      "Epoch 478/500\n",
      "396/396 [==============================] - 0s - loss: 0.1882 - val_loss: 0.3359\n",
      "Epoch 479/500\n",
      "396/396 [==============================] - 0s - loss: 0.1909 - val_loss: 0.3205\n",
      "Epoch 480/500\n",
      "396/396 [==============================] - 0s - loss: 0.1956 - val_loss: 0.3596\n",
      "Epoch 481/500\n",
      "396/396 [==============================] - 0s - loss: 0.1932 - val_loss: 0.3135\n",
      "Epoch 482/500\n",
      "396/396 [==============================] - 0s - loss: 0.1977 - val_loss: 0.3724\n",
      "Epoch 483/500\n",
      "396/396 [==============================] - 0s - loss: 0.2014 - val_loss: 0.3093\n",
      "Epoch 484/500\n",
      "396/396 [==============================] - 0s - loss: 0.1927 - val_loss: 0.3429\n",
      "Epoch 485/500\n",
      "396/396 [==============================] - 0s - loss: 0.1935 - val_loss: 0.3004\n",
      "Epoch 486/500\n",
      "396/396 [==============================] - 0s - loss: 0.1915 - val_loss: 0.3207\n",
      "Epoch 487/500\n",
      "396/396 [==============================] - 0s - loss: 0.1898 - val_loss: 0.3136\n",
      "Epoch 488/500\n",
      "396/396 [==============================] - 0s - loss: 0.1904 - val_loss: 0.3262\n",
      "Epoch 489/500\n",
      "396/396 [==============================] - 0s - loss: 0.1930 - val_loss: 0.3110\n",
      "Epoch 490/500\n",
      "396/396 [==============================] - 0s - loss: 0.1887 - val_loss: 0.3320\n",
      "Epoch 491/500\n",
      "396/396 [==============================] - 0s - loss: 0.1924 - val_loss: 0.3227\n",
      "Epoch 492/500\n",
      "396/396 [==============================] - 0s - loss: 0.1907 - val_loss: 0.3430\n",
      "Epoch 493/500\n",
      "396/396 [==============================] - 0s - loss: 0.1876 - val_loss: 0.3116\n",
      "Epoch 494/500\n",
      "396/396 [==============================] - 0s - loss: 0.1925 - val_loss: 0.3513\n",
      "Epoch 495/500\n",
      "396/396 [==============================] - 0s - loss: 0.1917 - val_loss: 0.3158\n",
      "Epoch 496/500\n",
      "396/396 [==============================] - 0s - loss: 0.1883 - val_loss: 0.3456\n",
      "Epoch 497/500\n",
      "396/396 [==============================] - 0s - loss: 0.1895 - val_loss: 0.3020\n",
      "Epoch 498/500\n",
      "396/396 [==============================] - 0s - loss: 0.1962 - val_loss: 0.3676\n",
      "Epoch 499/500\n",
      "396/396 [==============================] - 0s - loss: 0.1987 - val_loss: 0.3196\n",
      "Epoch 500/500\n",
      "396/396 [==============================] - 0s - loss: 0.1873 - val_loss: 0.3261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15485428ac8>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(X_train[:-2],Y_train, batch_size=512,\n",
    "\t    epochs=500,\n",
    "\t    validation_split=0.05)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/105 [========>.....................] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29639356732368471"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test)\n",
    "#model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#score,acc=model.evaluate(X_test,Y_test)\n",
    "#print('Score:',score)\n",
    "#print('Accuracy',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "\n",
    "predicted = (np.sign(pred-0.45)+1)/2*50\n",
    "r2=sk.metrics.r2_score(Y_test,predicted)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGOClCUAY4wJUpYAjDEmSP0/fxjphWCpAlAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d3ba28f358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start =250\n",
    "stop = 331\n",
    "plt.plot(predicted[start:stop],'r')#prediction is in red.\n",
    "plt.plot(features[start:stop,3],'b')#actual in blue.\n",
    "plt.plot(Y_test[start:stop]*50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "98be9b8c-34f9-4377-9435-36bd5a9068b9",
    "_uuid": "ebcd231514ab6e9895b912694a3ce7fb19f25c12"
   },
   "source": [
    "**lets try to generalize on ethereum price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9689a9fe-26e9-4a4c-b11b-6beb27c709c6",
    "_uuid": "e71375cda496d1702f6ff47ce7d20e462cf30aaa",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_eth = eth[[\"Open\",\"High\",\"Low\",\"Close\"]].values\n",
    "print(features_eth.shape)\n",
    "\n",
    "#we change the data to have something more generalizeable, lets say [ %variation , %high, %low]\n",
    "price_variation = (1- (features_eth[:,0]/features_eth[:,3]))*100\n",
    "highs = (features_eth[:,1]/np.maximum(features_eth[:,0],features_eth[:,3]) -1)*100\n",
    "lows = (features_eth[:,2]/np.minimum(features_eth[:,0],features_eth[:,3]) -1)*100\n",
    "\n",
    "X_test = np.array([price_variation , highs, lows]).transpose()\n",
    "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
    "Y_test = np.array((np.sign(features_eth[2:,3]/features_eth[:-2,3]-1)+1)/2)\n",
    "print(Y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3033e2bb-9de3-44f9-9efc-d9b4e269c952",
    "_uuid": "b52992dde6b0444537f085e074c60fc56e989725",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model.evaluate(X_test[:-2],Y_test)\n",
    "#model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "score,acc=model.evaluate(X_test[:-2],Y_test)\n",
    "print('Score:',score)\n",
    "print('Accuracy',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "73d71878-d5d8-4d42-9f71-8023bda42697",
    "_uuid": "f73a1d5e4c712ebb8aa95ffcdb8c54be07f83ff4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "\n",
    "predicted = (np.sign(pred-0.45)+1)/2*50\n",
    "print(predicted)\n",
    "print('test')\n",
    "print(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7a8fc713-5f5d-4393-b743-57583777d992",
    "_uuid": "b2904931455a7cda0dee2e9fd0691026371f8731",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#lets plot the last predictions in comparison to the actual variations\n",
    "start =650\n",
    "stop = 700\n",
    "plt.plot(predicted[start:stop],'r')#prediction is in red.\n",
    "plt.plot(features_eth[start:stop,3],'b')#actual in blue.\n",
    "plt.plot(Y_test[start:stop]*50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2e17f8f2-a4be-42c2-84d5-768e99062960",
    "_uuid": "d6c640defa76e97b29d5108e576ba0b44750a622",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c825edcd-19a7-4fc4-b173-363636655357",
    "_uuid": "e82418ac27b4175a99462b760926b0d2abfb618e"
   },
   "source": [
    "Now you just have to refresh this every day, and buy some ETH when my super prediction algorithm tells you the price will go up! Don't thank me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eafb5558-1cd0-4f24-a89d-5846c1ee5ba6",
    "_uuid": "018bee012fb0eda7eedbec1e05711224734c5ef4"
   },
   "source": [
    "Thanks for reading.  Have fun if you want to predict the future of cryptocoins!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7dfe7c9e-c612-475a-ab6d-b8b401ad6594",
    "_uuid": "d1b972ee36881b8dd399fd23ad27174f0bb5cf09",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
